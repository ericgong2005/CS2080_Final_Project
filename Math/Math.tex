\documentclass{article}
\usepackage{amsmath,amssymb}
\usepackage{amsthm}            % for theorem environments
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{fullpage}

% Define theorem environments
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}

\begin{document}

\section{What Standard SGD Does}
Stochastic Gradient Descent fits model parameters $\theta$ by taking small steps that decrease the calculated loss over the dataset.  At each step:
\begin{itemize}
  \item Pick a random batch of $b$ examples.
  \item Compute the average gradient.
  \item Update $\theta$ by moving in the negative gradient direction.
\end{itemize}

\begin{algorithm}
\caption{Standard SGD}\label{alg:sgd}
\begin{algorithmic}[1]
\REQUIRE Data $\{x_i\}_{i=1}^N$, loss $L(\theta,x)$, initial $\theta_0$, 
learning rates $\{\eta_t\}$, batch size $b$, steps $T$.
\FOR{$t=1$ \TO $T$}
  \STATE Sample mini‑batch $B_t$ of size $b$.
  \STATE $g_t \leftarrow \frac1b\sum_{x\in B_t}\nabla_\theta L(\theta_{t-1},x)$.
  \STATE $\theta_t \leftarrow \theta_{t-1} - \eta_t\,g_t$.
\ENDFOR
\end{algorithmic}
\end{algorithm}

\section{Making SGD Private}
DP‑SGD ensures that no particular sample is able to have an outsized impact on the gradient at any step of iteration \cite{DR14}. 

This is accomplished by clipping each examples gradient, to limit the impact of each sample, and then adding noise to hide individual contribution differences:
\begin{enumerate}
  \item Clipping each per‐example gradient to norm at most $C$.
  \item Adding Gaussian noise of standard deviation $\sigma\,C$ to the averaged gradient.
\end{enumerate}

\begin{algorithm}
\caption{Differentially Private SGD}\label{alg:dpsgd}
\begin{algorithmic}[1]
\REQUIRE Data $\{x_i\}$, loss $L(\theta,x)$, initial $\theta_0$, $\{\eta_t\}$, $b$, $C$, $\sigma$, $T$.
\FOR{$t=1$ \TO $T$}
  \STATE Sample $B_t$ of size $b$.
  \FOR{each $x\in B_t$}
    \STATE $g_t(x)\leftarrow\nabla_\theta L(\theta_{t-1},x)$.
    \STATE $\bar g_t(x)\leftarrow g_t(x)/\max\!\bigl(1,\|g_t(x)\|_2/C\bigr)$.
  \ENDFOR
  \STATE $\bar g_t \leftarrow \frac1b\sum_{x\in B_t}\bar g_t(x)$.
  \STATE $\widetilde g_t \leftarrow \bar g_t + \mathcal{N}(0,\sigma^2 C^2 I)$.
  \STATE $\theta_t \leftarrow \theta_{t-1} - \eta_t\,\widetilde g_t$.
\ENDFOR
\end{algorithmic}
\end{algorithm}

\section{Various values of $\sigma$}
There are various methods by which we quanitfy the amount of noise added. The tighter the bounds we need, the better.

Let $q=b/N$ be the sampled proportion and we target overall $(\varepsilon,\delta)$‑DP.

\subsection{1. Naïve Composition Theorem}
Each iteration is viewed as $(\varepsilon',\delta')$‑DP, and composing $T$ of them yields $(T\varepsilon',T\delta')$‑DP.  To achieve $(\varepsilon,\delta)$:

\[
\varepsilon'=\frac\varepsilon T,\quad
\delta'=\frac\delta{q\,T}.
\]

The Gaussian mechanism (with sensitivity $C$) then requires
\[
\sigma_{\rm naive}
=\frac{\sqrt{2\ln(1.25/\delta')}}{\varepsilon'}
=\frac{q\,T\,\sqrt{2\ln\!\bigl(\tfrac{1.25\,q\,T}{\delta}\bigr)}}{\varepsilon}.
\]
as per the works of Dwork \cite{DR14}.

\subsection{2. Strong Composition Theorem}
Advanced composition gives
\[
\bigl(\widetilde\varepsilon,\;T\delta'+\delta''\bigr)\text{-DP},\quad
\widetilde\varepsilon
=\varepsilon'\sqrt{2T\ln\tfrac1{\delta''}}
+T\,\varepsilon'\frac{e^{\varepsilon'}-1}{e^{\varepsilon'}+1}.
\]
For $\varepsilon'\le1$, this simplifies and leads to
\[
\sigma_{\rm strong}
=O\!\Bigl(\frac{q\,\sqrt{T\,\ln(1/\delta)\,\ln(T/\delta)}}{\varepsilon}\Bigr).
\]
once again taken from the works of Dwork \cite{DR14}.

\subsection{Note: Naïve vs.\ Advanced}
We compare the two noise scales by their ratio:
\[
\frac{\sigma_{\rm strong}}{\sigma_{\rm naive}}
=O\!\Bigl(\frac{q\,\sqrt{T\,\ln(1/\delta)\,\ln(T/\delta)}/\varepsilon}
{q\,T\,\sqrt{2\ln(1.25\,q\,T/\delta)}/\varepsilon}\Bigr)
=O\!\Bigl(\sqrt{\frac{\ln(1/\delta)\,\ln(T/\delta)}{2\,T\,\ln(1.25\,q\,T/\delta)}}\Bigr).
\]
For large $T$, $\ln(T/\delta)\approx\ln T$ and $\ln(1.25\,q\,T/\delta)\approx\ln T$, so
\[
\frac{\sigma_{\rm strong}}{\sigma_{\rm naive}}
=O\!\Bigl(\sqrt{\tfrac{\ln T}{T}}\Bigr)
=O\!\bigl(T^{-1/2}\bigr).
\]
Thus, advanced composition requires asymptotically $\sqrt{T}$ times less noise.

\subsection{Moments Accountant Method}
While Advanced Composition provides a good bound, better bounds exist for the case of DP SGD \cite{AAH16}. In particular, it has been shown that a method known as the Moments Accountant Method gives a noise variance bound of:

\begin{theorem}[Moments Accountant, {\cite[Thm.~1]{AAH16}}]
If 
\[
\sigma \ge c\,\frac{q\,\sqrt{T\,\ln(1/\delta)}}{\varepsilon},
\]
then DP‑SGD satisfies $(\varepsilon,\delta)$‑DP.
\end{theorem}

This removes the extra $\sqrt{\ln(T/\delta)}$ factor, making this a tighter bound on noise than the Advanced composition theorem.

\section{Training Longer and Learning Rates}
\begin{itemize}
  \item Multiple epochs ($E\,T$ steps) scale privacy loss by $E$ for the naïve method, by $\sqrt{E}$ using advanced composition, and only by a constant factor when using the moments accountant method.
  \item Changing $\eta_t$ affects convergence but not the privacy analysis: only the number of noisy steps and noise level matter.
\end{itemize}

\bibliographystyle{plain}
\bibliography{references}

\end{document}

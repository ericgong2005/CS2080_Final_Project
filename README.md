# Evaluating Differentially Private Stochastic Gradient Descent Optimizers for Training Transformer Language Models

The remarkable ability of LLMs to generalize to a diverse variety of tasks is made possible by training upon immense corpuses of data. These data, scraped from internet sources with little to no filtering and oversight can risk the contamination of LLM's model weights with sensitive and private information, which may now become readily available to all parties utilizing the model. As such, providing formal guarantees on limiting the extent to which any particular secret or private information found in the training data can influence model weights is of critical interest. We thus demonstrate the efficacy of differentially private stochastic gradient descent optimizers at providing privacy guarantees at training time.
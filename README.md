# CS2080_Final_Project
Evaluating Differentially Private Transformer Language Model Training Frameworks

## Conda installs:
 - conda install pytorch torchvision torchaudio

## Usage:
 - Run with python transformer_model.py

## Sample Output:

Using mps

Number of parameters:  84746 

step 0: train loss 5.5806, val loss 5.5751
step 5: train loss 3.6805, val loss 3.7782
step 10: train loss 3.4321, val loss 3.7338
step 15: train loss 3.1852, val loss 3.2657
step 20: train loss 3.0988, val loss 3.3923
step 25: train loss 2.7510, val loss 3.1707
step 30: train loss 2.8753, val loss 3.3257
step 35: train loss 2.7398, val loss 3.2344
step 40: train loss 2.7066, val loss 3.1020
step 45: train loss 2.8007, val loss 2.8633
step 50: train loss 2.8154, val loss 3.1802
step 55: train loss 2.5469, val loss 2.9651
step 60: train loss 2.6420, val loss 3.1063
step 65: train loss 2.7623, val loss 3.1471
step 70: train loss 2.5267, val loss 3.1289
step 75: train loss 2.6599, val loss 3.0340
step 80: train loss 2.8095, val loss 3.2197
step 85: train loss 2.7684, val loss 3.3050
step 90: train loss 2.7784, val loss 3.2815
step 95: train loss 2.6516, val loss 2.9567
The cat in the hat rake.am, not!our!! will Tree little like! not Things..Tricks,,,"
"Oh  car not KiteAnd?"
"""Now
I.?,!I??
I me no and cat!
Can andIn. no saw!-Do is